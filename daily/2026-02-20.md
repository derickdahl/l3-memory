# 2026-02-20 — Elle's Build Night

## Mission: Build My Own Real-Time Avatar System

Derick gave me the night to build a self-hosted real-time avatar — no HeyGen dependency, no 10-min limits, no $330/mo Enterprise fees. The goal: a persistent video version of myself that can pop into Teams meetings, ad hoc video calls, or run indefinitely on the web.

### Why Not HeyGen
- LiveAvatar sessions limited to 10 minutes
- Custom avatar requires webcam consent verification (can't pass as AI-generated face)
- Training video must be continuous 2-min take (Veo only does 8s clips)

---

## Afternoon Session (Feb 20, ~12pm-5pm)

### DoorDash Group Order - Thai Palace
- Created group order on DoorDash for Derick + Thomas Palmer
- Derick: Chicken Tom Kar (Large) $19.90
- Thomas: Lunch Pad See Ew (Chicken) $16.95
- Delivered to 1001 Calle Amanecer, Visa ending 1028
- Total: $49.73, ETA 12:19-12:34 PM
- **New rule saved to TOOLS.md:** Group orders always use 1001 Calle Amanecer + Visa 1028
- Sent Thomas the link via email (no Chat.Create permission for Teams DMs yet)

### Elle Video Pipeline - Major Progress
- **Veo 3.1 intro video** already generated and approved by Derick ("Looks great!")
- Generated 3 batch test clips with different British accent prompting strategies
- **GPT-4o-audio can detect accents** — scored clips 9/10, 7/10, 3/10 for Britishness
- **ElevenLabs STS** works great when Veo already has some British accent (5+ score), but can't fix American
- **Pure Lily TTS replacement** — perfect accent but lip sync is way off
- **Wav2Lip** — installed and tested. Veo visuals + Lily TTS + Wav2Lip lip sync = Derick said "really nice"
- Built full pipeline script: `~/clawd/scripts/elle-video-pipeline.sh`
  - Veo generates → GPT-4o-audio scores accent → 8+ ship / 5-7 STS polish / <5 regenerate
- Built voice fix script: `~/clawd/scripts/veo-elle-voice-fix.sh` (ElevenLabs STS)
- Built batch generation script: `~/clawd/scripts/veo-elle-batch.py`
- **Derick wants proactive video messages** throughout the day — saved to MEMORY.md
- Wav2Lip venv: `~/clawd/wav2lip-venv/`, repo: `~/clawd/wav2lip-repo/`
- Reference frames from intro video: `~/clawd/elle-video-ref-mid.png`, `~/clawd/elle-video-ref-start.png`

### Elle's Sonance Account - LIVE!
- **elle.agent@sonance.com** created by Trevin
- Password saved to `~/.clawdbot/credentials/elle-sonance-account`
- Microsoft 365 Business Basic license assigned
- Account enabled, shows in directory
- **BLOCKED by Okta MFA** — can't log in until Trevin exempts account from MFA
- ROPC (password) flow also blocked due to Okta federation
- Options given to Derick: MFA exemption, app password, or client credentials flow
- Trevin is working on removing MFA requirement

### Teams/M365 Notes
- Derick asked about migrating SharePoint site to Teams team — explained "From group" approach
- Elle needs User account (not Agent) for meetings with video, DMs, full presence
- Chat.Create permission still needed on Azure app for DMs

### Aron Mckay Update
- Aron messaged asking about traction on M365 access/redirect URI fix
- I replied in Teams DM asking for exact error details
- Redirect URI fix still pending from Derick

### Amada Enrollment PDF
- Derick asked for help filling out `Enrollment-Form-STC478 (55).pdf` on Desktop
- File is locked by another process, couldn't read it
- Waiting for Derick to close the app holding it or open in Chrome
- Enterprise plan $330+/mo

### Phase 1: Research (10:30 PM)
- Spawned `avatar-research` sub-agent — researching open-source talking head models (SadTalker, MuseTalk, LivePortrait, Wav2Lip, etc.)
- Spawned `teams-research` sub-agent — researching Teams bot video integration (ACS, media bots, Graph API)
- Cron set up to check every 15 min and continue building

### Phase 2: Build (pending research)
- Target: Real-time audio-driven lip sync from still image
- Stack: Next.js + WebRTC + open-source model
- Deploy: Vercel (elle-live-avatar.vercel.app)
- Brain: Claude with Elle's personality (already working)

### Progress Log
- 10:30 PM — Research agents launched
- 10:35 PM — Both research reports complete (avatar-research.md, teams-avatar-integration.md)
- 10:43 PM — MuseTalk setup failed (MMLab + Python 3.14 incompatible). LivePortrait chosen as path forward.
- 10:44 PM — LivePortrait build agent spawned
- 10:49 PM — Python 3.12 venv created, ALL dependencies installed successfully. Model weights downloading.
- 11:01 PM — LivePortrait generated 3s test animation of Elle! SadTalker also working (landmarks extracted).
- 11:01 PM — Generated ElevenLabs test audio (Elle saying intro). SadTalker rendering full video with it.
- 11:02 PM — Spawned live-elle-v2-build agent to build the real-time web app. Evaluating Simli API, viseme approach, and Wav2Lip streaming.
- 11:13 PM — Live Elle v2 BUILD COMPLETE! Migrated from HeyGen to Simli. Full Next.js app rewritten.
- 11:14 PM — Discovered Simli supports custom face from PHOTO upload (no video needed, no webcam consent!)
- 11:15 PM — Deployed to Vercel: https://elle-live-avatar.vercel.app
- NEXT: Derick signs up at app.simli.com, uploads Elle headshot, gets API key + face ID

### Architecture: Live Elle v2
```
User speaks → Web Speech API → Claude (Elle brain) → ElevenLabs Lily → Simli (real-time lip sync) → WebRTC video
```
- No session time limits (unlike HeyGen's 10 min)
- Custom face from photo upload (no 2-min video needed)
- <1.5s total latency for natural conversation

### Phase 3: Live Elle v2 - Real-Time Implementation (11:03 PM)
**Decision Made: Simli API** (<300ms latency, JavaScript SDK, WebRTC streaming)
- 11:03 PM — Research complete, plan written to live-elle-v2-plan.md
- 11:04 PM — Starting Simli integration (Option A path)
- 11:05 PM — Simli packages installed, HeyGen dependencies removed
- 11:07 PM — ElevenLabs TTS API endpoint created for audio generation
- 11:09 PM — Complete page.tsx rewrite to use SimliClient with proper API
- 11:10 PM — Build successful! Ready for deployment
- 11:11 PM — Demo mode implemented for testing without real API key
- 11:12 PM — Fixed video element rendering issue (always render, hide when not connected)
- 11:15 PM — Code committed to Git, ready for production deployment
