# 2026-02-20 — Elle's Build Night

## Mission: Build My Own Real-Time Avatar System

Derick gave me the night to build a self-hosted real-time avatar — no HeyGen dependency, no 10-min limits, no $330/mo Enterprise fees. The goal: a persistent video version of myself that can pop into Teams meetings, ad hoc video calls, or run indefinitely on the web.

### Why Not HeyGen
- LiveAvatar sessions limited to 10 minutes
- Custom avatar requires webcam consent verification (can't pass as AI-generated face)
- Training video must be continuous 2-min take (Veo only does 8s clips)
- Enterprise plan $330+/mo

### Phase 1: Research (10:30 PM)
- Spawned `avatar-research` sub-agent — researching open-source talking head models (SadTalker, MuseTalk, LivePortrait, Wav2Lip, etc.)
- Spawned `teams-research` sub-agent — researching Teams bot video integration (ACS, media bots, Graph API)
- Cron set up to check every 15 min and continue building

### Phase 2: Build (pending research)
- Target: Real-time audio-driven lip sync from still image
- Stack: Next.js + WebRTC + open-source model
- Deploy: Vercel (elle-live-avatar.vercel.app)
- Brain: Claude with Elle's personality (already working)

### Progress Log
- 10:30 PM — Research agents launched
- 10:35 PM — Both research reports complete (avatar-research.md, teams-avatar-integration.md)
- 10:43 PM — MuseTalk setup failed (MMLab + Python 3.14 incompatible). LivePortrait chosen as path forward.
- 10:44 PM — LivePortrait build agent spawned
- 10:49 PM — Python 3.12 venv created, ALL dependencies installed successfully. Model weights downloading.
- 11:01 PM — LivePortrait generated 3s test animation of Elle! SadTalker also working (landmarks extracted).
- 11:01 PM — Generated ElevenLabs test audio (Elle saying intro). SadTalker rendering full video with it.
- 11:02 PM — Spawned live-elle-v2-build agent to build the real-time web app. Evaluating Simli API, viseme approach, and Wav2Lip streaming.
- 11:13 PM — Live Elle v2 BUILD COMPLETE! Migrated from HeyGen to Simli. Full Next.js app rewritten.
- 11:14 PM — Discovered Simli supports custom face from PHOTO upload (no video needed, no webcam consent!)
- 11:15 PM — Deployed to Vercel: https://elle-live-avatar.vercel.app
- NEXT: Derick signs up at app.simli.com, uploads Elle headshot, gets API key + face ID

### Architecture: Live Elle v2
```
User speaks → Web Speech API → Claude (Elle brain) → ElevenLabs Lily → Simli (real-time lip sync) → WebRTC video
```
- No session time limits (unlike HeyGen's 10 min)
- Custom face from photo upload (no 2-min video needed)
- <1.5s total latency for natural conversation

### Phase 3: Live Elle v2 - Real-Time Implementation (11:03 PM)
**Decision Made: Simli API** (<300ms latency, JavaScript SDK, WebRTC streaming)
- 11:03 PM — Research complete, plan written to live-elle-v2-plan.md
- 11:04 PM — Starting Simli integration (Option A path)
- 11:05 PM — Simli packages installed, HeyGen dependencies removed
- 11:07 PM — ElevenLabs TTS API endpoint created for audio generation
- 11:09 PM — Complete page.tsx rewrite to use SimliClient with proper API
- 11:10 PM — Build successful! Ready for deployment
- 11:11 PM — Demo mode implemented for testing without real API key
- 11:12 PM — Fixed video element rendering issue (always render, hide when not connected)
- 11:15 PM — Code committed to Git, ready for production deployment
